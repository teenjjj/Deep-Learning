{"cells":[{"cell_type":"markdown","metadata":{},"source":["# MIS 583 Assignment 4: Self-supervised and transfer learning on CIFAR10"]},{"cell_type":"markdown","metadata":{},"source":["Before we start, please put your name and SID in following format: <br>\n",": LASTNAME Firstname, ?00000000   //   e.g.) 李晨愷 M114020035"]},{"cell_type":"markdown","metadata":{},"source":["**Your Answer:**    \n","Hi I'm 陳羽楨, B094020019."]},{"cell_type":"markdown","metadata":{"id":"IWMWW8Ab_345"},"source":["## Google Colab Setup\n","Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n","\n","Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"vH4wc4iD_6w_"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Um5DJvBwb6xT"},"source":["# Data Setup (5 points)\n","\n","The first thing to do is implement a dataset class to load rotated CIFAR10 images with matching labels. Since there is already a CIFAR10 dataset class implemented in `torchvision`, we will extend this class and modify the `__get_item__` method appropriately to load rotated images.\n","\n","Each rotation label should be an integer in the set {0, 1, 2, 3} which correspond to rotations of 0, 90, 180, or 270 degrees respectively."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"oHkeNUOKiFbP"},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as Func\n","import numpy as np\n","import random\n","\n","\n","def rotate_img(img, rot):\n","    if rot == 0: # 0 degrees rotation\n","        return img\n","    #######################################################################\n","    #        TODO: Implement rotate_img() - return the rotated img        #                           \n","    #######################################################################\n","    elif rot == 1: # 90 degrees \n","        return Func.rotate(img, 90)\n","    elif rot == 2: # 180 degrees \n","        return Func.rotate(img, 180)\n","    elif rot == 3: # 270 degrees \n","        return Func.rotate(img, 270)\n","    else:\n","        raise ValueError('rotation should be 0, 90, 180, or 270 degrees')\n","\n","    #######################################################################\n","    #                           End of your code                          #\n","    #######################################################################\n","\n","class CIFAR10Rotation(torchvision.datasets.CIFAR10):\n","\n","    def __init__(self, root, train, download, transform) -> None:\n","        super().__init__(root=root, train=train, download=download, transform=transform)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index: int):\n","        image, cls_label = super().__getitem__(index)\n","\n","        # randomly select image rotation\n","        rotation_label = random.choice([0, 1, 2, 3])\n","        image_rotated = rotate_img(image, rotation_label)\n","\n","        rotation_label = torch.tensor(rotation_label).long()\n","        return image, image_rotated, rotation_label, torch.tensor(cls_label).long()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"CCBSpNWpb8uw"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","batch_size = 128\n","\n","trainset = CIFAR10Rotation(root='./data', train=True,\n","                                        download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = CIFAR10Rotation(root='./data', train=False,\n","                                       download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=2)"]},{"cell_type":"markdown","metadata":{"id":"dOCWMyGhVOJB"},"source":["Show some example images and rotated images with labels:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"A9wN4BJWVMzB"},"outputs":[{"name":"stderr","output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"name":"stdout","output_type":"stream","text":["Class labels:  horse plane car   truck\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Rotation labels:  90    270   90    180  \n"]}],"source":["import matplotlib.pyplot as plt\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","rot_classes = ('0', '90', '180', '270')\n","\n","\n","def imshow(img):\n","    # unnormalize\n","    img = transforms.Normalize((0, 0, 0), (1/0.2023, 1/0.1994, 1/0.2010))(img)\n","    img = transforms.Normalize((-0.4914, -0.4822, -0.4465), (1, 1, 1))(img)\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","\n","dataiter = iter(trainloader)\n","images, rot_images, rot_labels, labels = next(dataiter)\n","\n","# print images and rotated images\n","img_grid = imshow(torchvision.utils.make_grid(images[:4], padding=0))\n","print('Class labels: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n","img_grid = imshow(torchvision.utils.make_grid(rot_images[:4], padding=0))\n","print('Rotation labels: ', ' '.join(f'{rot_classes[rot_labels[j]]:5s}' for j in range(4)))"]},{"cell_type":"markdown","metadata":{"id":"unCucbHexG4W"},"source":["# Evaluation code"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"pptQRpqK0rOl"},"outputs":[],"source":["import time\n","\n","def run_test(net, testloader, criterion, task):\n","    correct = 0\n","    total = 0\n","    avg_test_loss = 0.0\n","    # since we're not training, we don't need to calculate the gradients for our outputs\n","    with torch.no_grad():\n","        for images, images_rotated, labels, cls_labels in testloader:\n","            if task == 'rotation':\n","              images, labels = images_rotated.to(device), labels.to(device)\n","            elif task == 'classification':\n","              images, labels = images.to(device), cls_labels.to(device)\n","            #######################################################################\n","            # TODO: Calculate outputs by running images through the network       #\n","            # The class with the highest energy is what we choose as prediction   #\n","            #######################################################################\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0) #總共幾類\n","            correct += (predicted == labels).sum().item() #對的有幾個\n","            #######################################################################\n","            #                           End of your code                          #\n","            #######################################################################\n","            avg_test_loss += criterion(outputs, labels)  / len(testloader)\n","    print('TESTING:')\n","    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n","    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"hf698c16A9k5"},"outputs":[],"source":["def adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs=30):\n","    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n","    lr = init_lr * (0.1 ** (epoch // decay_epochs))\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","#之後可改learning rate scheduler"]},{"cell_type":"markdown","metadata":{"id":"3lYdnb1Wsta_"},"source":["# Train a ResNet18 on the rotation task (9 points)\n","\n","In this section, we will train a ResNet18 model **from scratch** on the rotation task. The input is a rotated image and the model predicts the rotation label. See the Data Setup section for details."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"knAiwdURvBHk"},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"markdown","metadata":{},"source":["### Notice: You should not use pretrained weights from ImageNet."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"235MEIUgsv65"},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=4, bias=True)\n",")\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18\n","\n","net = resnet18(weights = None, num_classes=4) # Do not modify this line.\n","net = net.to(device)\n","print(net) # print your model and check the num_classes is correct"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Vuhiw0ZoszAd"},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","################################################################################\n","# TODO: Define loss and optmizer functions                                     #\n","# Try any loss or optimizer function and learning rate to get better result    #\n","# hint: torch.nn and torch.optim                                               #\n","################################################################################\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=3e-4)\n","################################################################################\n","#                               End of your code                               #\n","################################################################################\n","criterion = criterion.to(device)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"WleH-YBgs0rq"},"outputs":[],"source":["# Both the self-supervised rotation task and supervised CIFAR10 classification are\n","# trained with the CrossEntropyLoss, so we can use the training loop code.\n","\n","def train(net, criterion, optimizer, num_epochs, decay_epochs, init_lr, task):\n","\n","    for epoch in range(num_epochs):  # loop over the dataset multiple times\n","\n","        running_loss = 0.0\n","        running_correct = 0.0\n","        running_total = 0.0\n","        start_time = time.time()\n","\n","        net.train()\n","\n","        for i, (imgs, imgs_rotated, rotation_label, cls_label) in enumerate(trainloader, 0):\n","            adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n","            ######################################################################################################\n","            # TODO: Set the data to the correct device; Different task will use different inputs and labels      #  \n","            # TODO: Zero the parameter gradients                                                                 #\n","            # TODO: forward + backward + optimize                                                                #\n","            # TODO: Get predicted results                                                                        #\n","            ######################################################################################################\n","            if task == 'rotation':\n","              images, labels = imgs_rotated.to(device), rotation_label.to(device)\n","            elif task == 'classification':\n","              images, labels = imgs.to(device), cls_label.to(device)\n","            \n","            optimizer.zero_grad()\n","            outputs = net(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            _, predicted = torch.max(outputs, 1)\n","            ######################################################################################################\n","            #                               End of your code                                                     #\n","            ######################################################################################################                                            \n","\n","\n","            # print statistics\n","            print_freq = 100\n","            running_loss += loss.item()\n","\n","            # calc acc\n","            running_total += labels.size(0)\n","            running_correct += (predicted == labels).sum().item()\n","\n","            if i % print_freq == (print_freq - 1):    # print every 2000 mini-batches\n","                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100*running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n","                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n","                start_time = time.time()\n","        ######################################################################################################\n","        # TODO: Run the run_test() function after each epoch; Set the model to the evaluation mode.          #\n","        ######################################################################################################\n","        net.eval()\n","        run_test(net, testloader, criterion, task) \n","        ######################################################################################################\n","        #                               End of your code                                                     #\n","        ######################################################################################################  \n","\n","    print('Finished Training')\n","    \n","    try:\n","        if trainloader:\n","            trainloader.shutdown()\n","        if testloader:\n","            testloader.shutdown()\n","    except Exception as e:\n","        pass"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"2u4AsfAKtaQS"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1,   100] loss: 0.688 acc: 74.02 time: 2.57\n","[1,   200] loss: 0.650 acc: 74.12 time: 2.26\n","[1,   300] loss: 0.646 acc: 74.34 time: 2.25\n","TESTING:\n","Accuracy of the network on the 10000 test images: 74.61 %\n","Average loss on the 10000 test images: 0.652\n","[2,   100] loss: 0.644 acc: 74.81 time: 2.34\n","[2,   200] loss: 0.632 acc: 74.98 time: 2.24\n","[2,   300] loss: 0.648 acc: 74.47 time: 2.26\n","TESTING:\n","Accuracy of the network on the 10000 test images: 75.44 %\n","Average loss on the 10000 test images: 0.618\n","[3,   100] loss: 0.628 acc: 74.80 time: 2.36\n","[3,   200] loss: 0.616 acc: 75.73 time: 2.31\n","[3,   300] loss: 0.627 acc: 75.62 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 75.67 %\n","Average loss on the 10000 test images: 0.634\n","[4,   100] loss: 0.828 acc: 66.93 time: 2.33\n","[4,   200] loss: 0.717 acc: 71.83 time: 2.25\n","[4,   300] loss: 0.677 acc: 73.44 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 75.62 %\n","Average loss on the 10000 test images: 0.620\n","[5,   100] loss: 0.629 acc: 74.98 time: 2.37\n","[5,   200] loss: 0.626 acc: 75.56 time: 2.26\n","[5,   300] loss: 0.613 acc: 75.73 time: 2.27\n","TESTING:\n","Accuracy of the network on the 10000 test images: 76.01 %\n","Average loss on the 10000 test images: 0.607\n","[6,   100] loss: 0.596 acc: 76.52 time: 2.36\n","[6,   200] loss: 0.604 acc: 76.48 time: 2.27\n","[6,   300] loss: 0.602 acc: 76.66 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 76.40 %\n","Average loss on the 10000 test images: 0.592\n","[7,   100] loss: 0.597 acc: 76.86 time: 2.36\n","[7,   200] loss: 0.587 acc: 77.12 time: 2.26\n","[7,   300] loss: 0.602 acc: 76.58 time: 2.26\n","TESTING:\n","Accuracy of the network on the 10000 test images: 75.66 %\n","Average loss on the 10000 test images: 0.634\n","[8,   100] loss: 0.586 acc: 77.11 time: 2.33\n","[8,   200] loss: 0.589 acc: 76.76 time: 2.28\n","[8,   300] loss: 0.600 acc: 76.86 time: 2.27\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.11 %\n","Average loss on the 10000 test images: 0.584\n","[9,   100] loss: 0.578 acc: 77.29 time: 2.39\n","[9,   200] loss: 0.580 acc: 77.59 time: 2.29\n","[9,   300] loss: 0.593 acc: 76.46 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.86 %\n","Average loss on the 10000 test images: 0.572\n","[10,   100] loss: 0.578 acc: 77.52 time: 2.37\n","[10,   200] loss: 0.570 acc: 77.85 time: 2.27\n","[10,   300] loss: 0.586 acc: 77.07 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.83 %\n","Average loss on the 10000 test images: 0.566\n","[11,   100] loss: 0.576 acc: 77.36 time: 2.38\n","[11,   200] loss: 0.568 acc: 78.20 time: 2.28\n","[11,   300] loss: 0.562 acc: 78.16 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.75 %\n","Average loss on the 10000 test images: 0.563\n","[12,   100] loss: 0.557 acc: 78.51 time: 2.35\n","[12,   200] loss: 0.558 acc: 78.11 time: 2.28\n","[12,   300] loss: 0.556 acc: 78.38 time: 2.26\n","TESTING:\n","Accuracy of the network on the 10000 test images: 77.21 %\n","Average loss on the 10000 test images: 0.592\n","[13,   100] loss: 0.565 acc: 78.04 time: 2.39\n","[13,   200] loss: 0.564 acc: 77.84 time: 2.27\n","[13,   300] loss: 0.567 acc: 78.30 time: 2.27\n","TESTING:\n","Accuracy of the network on the 10000 test images: 78.38 %\n","Average loss on the 10000 test images: 0.563\n","[14,   100] loss: 0.558 acc: 78.18 time: 2.40\n","[14,   200] loss: 0.558 acc: 78.30 time: 2.28\n","[14,   300] loss: 0.549 acc: 78.70 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 78.30 %\n","Average loss on the 10000 test images: 0.560\n","[15,   100] loss: 0.537 acc: 79.34 time: 2.32\n","[15,   200] loss: 0.551 acc: 78.04 time: 2.27\n","[15,   300] loss: 0.549 acc: 78.58 time: 2.23\n","TESTING:\n","Accuracy of the network on the 10000 test images: 79.15 %\n","Average loss on the 10000 test images: 0.540\n","[16,   100] loss: 0.512 acc: 80.31 time: 2.39\n","[16,   200] loss: 0.499 acc: 80.64 time: 2.27\n","[16,   300] loss: 0.509 acc: 80.35 time: 2.26\n","TESTING:\n","Accuracy of the network on the 10000 test images: 80.88 %\n","Average loss on the 10000 test images: 0.497\n","[17,   100] loss: 0.493 acc: 80.83 time: 2.36\n","[17,   200] loss: 0.487 acc: 81.45 time: 2.24\n","[17,   300] loss: 0.489 acc: 81.14 time: 2.24\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.17 %\n","Average loss on the 10000 test images: 0.493\n","[18,   100] loss: 0.487 acc: 81.38 time: 2.36\n","[18,   200] loss: 0.483 acc: 81.28 time: 2.29\n","[18,   300] loss: 0.472 acc: 81.55 time: 2.26\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.24 %\n","Average loss on the 10000 test images: 0.486\n","[19,   100] loss: 0.476 acc: 81.83 time: 2.37\n","[19,   200] loss: 0.479 acc: 81.52 time: 2.28\n","[19,   300] loss: 0.480 acc: 81.66 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.37 %\n","Average loss on the 10000 test images: 0.482\n","[20,   100] loss: 0.476 acc: 81.91 time: 2.35\n","[20,   200] loss: 0.475 acc: 81.54 time: 2.27\n","[20,   300] loss: 0.468 acc: 82.05 time: 2.25\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.56 %\n","Average loss on the 10000 test images: 0.479\n","[21,   100] loss: 0.472 acc: 81.58 time: 2.34\n","[21,   200] loss: 0.459 acc: 82.45 time: 2.25\n","[21,   300] loss: 0.465 acc: 81.96 time: 2.27\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.82 %\n","Average loss on the 10000 test images: 0.474\n","[22,   100] loss: 0.471 acc: 82.16 time: 2.37\n","[22,   200] loss: 0.469 acc: 82.01 time: 2.26\n","[22,   300] loss: 0.467 acc: 81.55 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.78 %\n","Average loss on the 10000 test images: 0.478\n","[23,   100] loss: 0.461 acc: 82.41 time: 2.39\n","[23,   200] loss: 0.458 acc: 82.66 time: 2.24\n","[23,   300] loss: 0.458 acc: 82.78 time: 2.26\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.94 %\n","Average loss on the 10000 test images: 0.475\n","[24,   100] loss: 0.460 acc: 82.12 time: 2.35\n","[24,   200] loss: 0.463 acc: 82.15 time: 2.28\n","[24,   300] loss: 0.464 acc: 82.16 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.28 %\n","Average loss on the 10000 test images: 0.470\n","[25,   100] loss: 0.469 acc: 82.00 time: 2.37\n","[25,   200] loss: 0.453 acc: 82.61 time: 2.27\n","[25,   300] loss: 0.462 acc: 82.23 time: 2.27\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.14 %\n","Average loss on the 10000 test images: 0.471\n","[26,   100] loss: 0.455 acc: 82.59 time: 2.37\n","[26,   200] loss: 0.456 acc: 82.47 time: 2.27\n","[26,   300] loss: 0.465 acc: 82.38 time: 2.26\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.80 %\n","Average loss on the 10000 test images: 0.473\n","[27,   100] loss: 0.459 acc: 82.34 time: 2.39\n","[27,   200] loss: 0.458 acc: 82.30 time: 2.28\n","[27,   300] loss: 0.460 acc: 82.20 time: 2.27\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.80 %\n","Average loss on the 10000 test images: 0.468\n","[28,   100] loss: 0.464 acc: 82.05 time: 2.35\n","[28,   200] loss: 0.456 acc: 82.61 time: 2.28\n","[28,   300] loss: 0.457 acc: 82.42 time: 2.26\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.21 %\n","Average loss on the 10000 test images: 0.463\n","[29,   100] loss: 0.442 acc: 82.90 time: 2.38\n","[29,   200] loss: 0.459 acc: 82.48 time: 2.29\n","[29,   300] loss: 0.454 acc: 82.57 time: 2.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.03 %\n","Average loss on the 10000 test images: 0.468\n","[30,   100] loss: 0.450 acc: 82.69 time: 2.35\n","[30,   200] loss: 0.459 acc: 82.65 time: 2.27\n","[30,   300] loss: 0.457 acc: 82.31 time: 2.30\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.59 %\n","Average loss on the 10000 test images: 0.460\n","[31,   100] loss: 0.452 acc: 82.56 time: 2.39\n","[31,   200] loss: 0.458 acc: 82.55 time: 2.29\n","[31,   300] loss: 0.451 acc: 82.55 time: 2.27\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.25 %\n","Average loss on the 10000 test images: 0.464\n","[32,   100] loss: 0.448 acc: 82.77 time: 2.39\n","[32,   200] loss: 0.448 acc: 82.69 time: 2.29\n","[32,   300] loss: 0.436 acc: 83.19 time: 2.27\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.22 %\n","Average loss on the 10000 test images: 0.461\n","[33,   100] loss: 0.449 acc: 82.87 time: 2.34\n","[33,   200] loss: 0.431 acc: 83.41 time: 2.27\n","[33,   300] loss: 0.447 acc: 82.66 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.38 %\n","Average loss on the 10000 test images: 0.462\n","[34,   100] loss: 0.444 acc: 83.30 time: 2.35\n","[34,   200] loss: 0.440 acc: 82.95 time: 2.26\n","[34,   300] loss: 0.451 acc: 82.68 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.09 %\n","Average loss on the 10000 test images: 0.467\n","[35,   100] loss: 0.439 acc: 83.20 time: 2.38\n","[35,   200] loss: 0.444 acc: 82.80 time: 2.28\n","[35,   300] loss: 0.444 acc: 82.80 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.58 %\n","Average loss on the 10000 test images: 0.463\n","[36,   100] loss: 0.453 acc: 82.65 time: 2.37\n","[36,   200] loss: 0.443 acc: 83.13 time: 2.27\n","[36,   300] loss: 0.453 acc: 82.62 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.75 %\n","Average loss on the 10000 test images: 0.456\n","[37,   100] loss: 0.446 acc: 82.95 time: 2.38\n","[37,   200] loss: 0.441 acc: 83.39 time: 2.29\n","[37,   300] loss: 0.438 acc: 83.09 time: 2.24\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.51 %\n","Average loss on the 10000 test images: 0.461\n","[38,   100] loss: 0.442 acc: 83.00 time: 2.37\n","[38,   200] loss: 0.448 acc: 83.00 time: 2.22\n","[38,   300] loss: 0.436 acc: 83.47 time: 2.25\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.76 %\n","Average loss on the 10000 test images: 0.461\n","[39,   100] loss: 0.448 acc: 83.21 time: 2.37\n","[39,   200] loss: 0.437 acc: 83.04 time: 2.27\n","[39,   300] loss: 0.445 acc: 82.98 time: 2.30\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.53 %\n","Average loss on the 10000 test images: 0.458\n","[40,   100] loss: 0.441 acc: 83.19 time: 2.36\n","[40,   200] loss: 0.435 acc: 83.41 time: 2.25\n","[40,   300] loss: 0.447 acc: 83.06 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.21 %\n","Average loss on the 10000 test images: 0.464\n","[41,   100] loss: 0.441 acc: 83.26 time: 2.33\n","[41,   200] loss: 0.447 acc: 82.71 time: 2.24\n","[41,   300] loss: 0.435 acc: 83.04 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.05 %\n","Average loss on the 10000 test images: 0.461\n","[42,   100] loss: 0.446 acc: 82.75 time: 2.37\n","[42,   200] loss: 0.450 acc: 82.70 time: 2.27\n","[42,   300] loss: 0.439 acc: 83.12 time: 2.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.36 %\n","Average loss on the 10000 test images: 0.459\n","[43,   100] loss: 0.446 acc: 82.78 time: 2.39\n","[43,   200] loss: 0.444 acc: 82.78 time: 2.29\n","[43,   300] loss: 0.428 acc: 83.09 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.56 %\n","Average loss on the 10000 test images: 0.460\n","[44,   100] loss: 0.441 acc: 83.23 time: 2.38\n","[44,   200] loss: 0.441 acc: 83.05 time: 2.29\n","[44,   300] loss: 0.455 acc: 82.76 time: 2.25\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.42 %\n","Average loss on the 10000 test images: 0.461\n","[45,   100] loss: 0.446 acc: 82.62 time: 2.35\n","[45,   200] loss: 0.441 acc: 83.23 time: 2.29\n","[45,   300] loss: 0.444 acc: 83.15 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.82 %\n","Average loss on the 10000 test images: 0.454\n","Finished Training\n"]}],"source":["train(net, criterion, optimizer, num_epochs=45, decay_epochs=15, init_lr=0.01, task='rotation')\n","################################\n","#     TODO: Save the model     #  \n","################################\n","torch.save(net.state_dict(), 'A4-1save.pt')\n","################################\n","#      End of your code        #  \n","################################"]},{"cell_type":"markdown","metadata":{"id":"PLLMRTS9rTnk"},"source":["## Fine-tuning on the pre-trained model (9 points)\n","\n","In this section, we will load the ResNet18 model pre-trained on the rotation task and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer.\n","\n","**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"S4nX4ExlrymI"},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18\n","\n","#####################################################\n","#     TODO: Load the pre-trained ResNet18 model     #  \n","#####################################################\n","net.load_state_dict(torch.load('A4-1save.pt'))\n","net.fc = nn.Linear(512,10)\n","print(net) # print your model and check the num_classes is correct\n","####################################################\n","#                End of your code                  #   \n","####################################################"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"kD44g-TxwYdU"},"outputs":[],"source":["from torch import nn\n","#################################################################################################\n","#   TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable     #\n","#################################################################################################\n","for name, child in net.named_children():\n","    if name not in ['layer4', 'fc']:\n","        for param in child.parameters():\n","            param.requires_grad = False\n","    else:\n","        for param in child.parameters():\n","            param.requires_grad = True\n","\n","net = net.to(device)\n","#################################################################################################\n","#                                          End of your code                                     #\n","#################################################################################################"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"9T5DX0efr4fh"},"outputs":[{"name":"stdout","output_type":"stream","text":["Params to learn:\n","\t layer4.0.conv1.weight\n","\t layer4.0.bn1.weight\n","\t layer4.0.bn1.bias\n","\t layer4.0.conv2.weight\n","\t layer4.0.bn2.weight\n","\t layer4.0.bn2.bias\n","\t layer4.0.downsample.0.weight\n","\t layer4.0.downsample.1.weight\n","\t layer4.0.downsample.1.bias\n","\t layer4.1.conv1.weight\n","\t layer4.1.bn1.weight\n","\t layer4.1.bn1.bias\n","\t layer4.1.conv2.weight\n","\t layer4.1.bn2.weight\n","\t layer4.1.bn2.bias\n","\t fc.weight\n","\t fc.bias\n"]}],"source":["# Print all the trainable parameters\n","params_to_update = net.parameters()\n","print(\"Params to learn:\")\n","params_to_update = []\n","for name,param in net.named_parameters():\n","    if param.requires_grad == True:\n","        params_to_update.append(param)\n","        print(\"\\t\",name)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"xb032dG700ph"},"outputs":[],"source":["# TODO: Define criterion and optimizer\n","# Note that your optimizer only needs to update the parameters that are trainable.\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=3e-4)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"3vLSwOo6sBjl"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1,   100] loss: 1.989 acc: 23.87 time: 2.61\n","[1,   200] loss: 1.583 acc: 40.38 time: 2.31\n","[1,   300] loss: 1.449 acc: 46.38 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 49.55 %\n","Average loss on the 10000 test images: 1.419\n","[2,   100] loss: 1.356 acc: 50.38 time: 2.42\n","[2,   200] loss: 1.375 acc: 49.92 time: 2.25\n","[2,   300] loss: 1.360 acc: 50.02 time: 2.24\n","TESTING:\n","Accuracy of the network on the 10000 test images: 53.02 %\n","Average loss on the 10000 test images: 1.305\n","[3,   100] loss: 1.318 acc: 52.25 time: 2.34\n","[3,   200] loss: 1.292 acc: 52.74 time: 2.25\n","[3,   300] loss: 1.286 acc: 53.37 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 54.11 %\n","Average loss on the 10000 test images: 1.313\n","[4,   100] loss: 1.292 acc: 52.48 time: 2.38\n","[4,   200] loss: 1.271 acc: 53.87 time: 2.27\n","[4,   300] loss: 1.269 acc: 54.62 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 55.68 %\n","Average loss on the 10000 test images: 1.238\n","[5,   100] loss: 1.278 acc: 53.87 time: 2.34\n","[5,   200] loss: 1.260 acc: 54.08 time: 2.28\n","[5,   300] loss: 1.256 acc: 54.94 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 56.34 %\n","Average loss on the 10000 test images: 1.215\n","[6,   100] loss: 1.248 acc: 55.35 time: 2.40\n","[6,   200] loss: 1.241 acc: 54.91 time: 2.30\n","[6,   300] loss: 1.238 acc: 55.33 time: 2.30\n","TESTING:\n","Accuracy of the network on the 10000 test images: 55.97 %\n","Average loss on the 10000 test images: 1.338\n","[7,   100] loss: 1.247 acc: 55.23 time: 2.39\n","[7,   200] loss: 1.234 acc: 55.11 time: 2.32\n","[7,   300] loss: 1.229 acc: 55.66 time: 2.33\n","TESTING:\n","Accuracy of the network on the 10000 test images: 56.45 %\n","Average loss on the 10000 test images: 1.247\n","[8,   100] loss: 1.231 acc: 55.38 time: 2.40\n","[8,   200] loss: 1.221 acc: 56.27 time: 2.28\n","[8,   300] loss: 1.213 acc: 55.67 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 57.18 %\n","Average loss on the 10000 test images: 1.218\n","[9,   100] loss: 1.217 acc: 56.34 time: 2.40\n","[9,   200] loss: 1.213 acc: 55.93 time: 2.32\n","[9,   300] loss: 1.220 acc: 55.85 time: 2.35\n","TESTING:\n","Accuracy of the network on the 10000 test images: 58.60 %\n","Average loss on the 10000 test images: 1.176\n","[10,   100] loss: 1.197 acc: 56.55 time: 2.45\n","[10,   200] loss: 1.192 acc: 57.17 time: 2.31\n","[10,   300] loss: 1.211 acc: 56.09 time: 2.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 58.24 %\n","Average loss on the 10000 test images: 1.187\n","[11,   100] loss: 1.160 acc: 58.23 time: 2.38\n","[11,   200] loss: 1.168 acc: 57.77 time: 2.31\n","[11,   300] loss: 1.161 acc: 58.09 time: 2.32\n","TESTING:\n","Accuracy of the network on the 10000 test images: 59.91 %\n","Average loss on the 10000 test images: 1.139\n","[12,   100] loss: 1.130 acc: 59.21 time: 2.37\n","[12,   200] loss: 1.147 acc: 58.19 time: 2.29\n","[12,   300] loss: 1.173 acc: 57.70 time: 2.30\n","TESTING:\n","Accuracy of the network on the 10000 test images: 59.85 %\n","Average loss on the 10000 test images: 1.138\n","[13,   100] loss: 1.136 acc: 59.23 time: 2.39\n","[13,   200] loss: 1.154 acc: 58.34 time: 2.31\n","[13,   300] loss: 1.143 acc: 58.57 time: 2.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 60.39 %\n","Average loss on the 10000 test images: 1.117\n","[14,   100] loss: 1.137 acc: 58.62 time: 2.41\n","[14,   200] loss: 1.144 acc: 58.80 time: 2.26\n","[14,   300] loss: 1.159 acc: 57.98 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 60.44 %\n","Average loss on the 10000 test images: 1.123\n","[15,   100] loss: 1.152 acc: 58.15 time: 2.40\n","[15,   200] loss: 1.144 acc: 58.95 time: 2.31\n","[15,   300] loss: 1.136 acc: 58.24 time: 2.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 60.31 %\n","Average loss on the 10000 test images: 1.146\n","[16,   100] loss: 1.156 acc: 58.12 time: 2.40\n","[16,   200] loss: 1.136 acc: 58.51 time: 2.31\n","[16,   300] loss: 1.138 acc: 58.85 time: 2.30\n","TESTING:\n","Accuracy of the network on the 10000 test images: 60.17 %\n","Average loss on the 10000 test images: 1.128\n","[17,   100] loss: 1.138 acc: 59.06 time: 2.40\n","[17,   200] loss: 1.136 acc: 58.75 time: 2.31\n","[17,   300] loss: 1.134 acc: 58.95 time: 2.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 60.02 %\n","Average loss on the 10000 test images: 1.138\n","[18,   100] loss: 1.142 acc: 58.70 time: 2.40\n","[18,   200] loss: 1.129 acc: 59.17 time: 2.31\n","[18,   300] loss: 1.141 acc: 58.99 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 60.81 %\n","Average loss on the 10000 test images: 1.111\n","[19,   100] loss: 1.136 acc: 58.64 time: 2.38\n","[19,   200] loss: 1.142 acc: 58.86 time: 2.29\n","[19,   300] loss: 1.127 acc: 59.12 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 60.29 %\n","Average loss on the 10000 test images: 1.127\n","[20,   100] loss: 1.131 acc: 59.19 time: 2.36\n","[20,   200] loss: 1.151 acc: 58.62 time: 2.28\n","[20,   300] loss: 1.134 acc: 59.07 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 60.23 %\n","Average loss on the 10000 test images: 1.121\n","Finished Training\n"]}],"source":["train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.02, task='classification')\n","\n","torch.save(net.state_dict(), 'A4-2save.pt')\n"]},{"cell_type":"markdown","metadata":{"id":"ghPNhcJBrcNj"},"source":["## Fine-tuning on the randomly initialized model (9 points)\n","In this section, we will randomly initialize a ResNet18 model and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"2RfXAh9vxXRB"},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18\n","#################################################\n","# TODO: Randomly initialize a ResNet18 model    #\n","#################################################\n","\n","#Truncated normal initialization\n","net= resnet18()\n","\n","def truncated_normal_init(m):\n","    if isinstance(m, nn.Conv2d or nn.Linear):\n","        torch.nn.init.trunc_normal_(m.weight, 0, 0.1) \n","net.apply(truncated_normal_init)\n","\n","net.fc = nn.Linear(512,10)\n","print(net) # print your model and check the num_classes is correct\n","#################################################\n","#              End of your code                 #\n","#################################################"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"fpx-SYAizt4p"},"outputs":[],"source":["#################################################################################################\n","# TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable       #\n","# To do this, you should set requires_grad=False for the frozen layers.                         #\n","#################################################################################################\n","for name, child in net.named_children():\n","    if name not in ['layer4', 'fc']:\n","        for param in child.parameters():\n","            param.requires_grad = False\n","    else:\n","        for param in child.parameters():\n","            param.requires_grad = True\n","\n","# net.fc = nn.Linear(512,10)\n","net = net.to(device)\n","#################################################################################################\n","#                                          End of your code                                     #\n","#################################################################################################\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"BUFWizbHxgm2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Params to learn:\n","\t layer4.0.conv1.weight\n","\t layer4.0.bn1.weight\n","\t layer4.0.bn1.bias\n","\t layer4.0.conv2.weight\n","\t layer4.0.bn2.weight\n","\t layer4.0.bn2.bias\n","\t layer4.0.downsample.0.weight\n","\t layer4.0.downsample.1.weight\n","\t layer4.0.downsample.1.bias\n","\t layer4.1.conv1.weight\n","\t layer4.1.bn1.weight\n","\t layer4.1.bn1.bias\n","\t layer4.1.conv2.weight\n","\t layer4.1.bn2.weight\n","\t layer4.1.bn2.bias\n","\t fc.weight\n","\t fc.bias\n"]}],"source":["# Print all the trainable parameters\n","params_to_update = net.parameters()\n","print(\"Params to learn:\")\n","params_to_update = []\n","for name,param in net.named_parameters():\n","    if param.requires_grad == True:\n","        params_to_update.append(param)\n","        print(\"\\t\",name)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"BxFrGj091AN_"},"outputs":[],"source":["# TODO: Define criterion and optimizer\n","# Note that your optimizer only needs to update the parameters that are trainable.\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=3e-4)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"GzRVy0MZxpoL"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1,   100] loss: 2.233 acc: 25.01 time: 2.42\n","[1,   200] loss: 1.915 acc: 30.57 time: 2.33\n","[1,   300] loss: 1.856 acc: 32.99 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 37.48 %\n","Average loss on the 10000 test images: 1.733\n","[2,   100] loss: 1.811 acc: 34.91 time: 2.39\n","[2,   200] loss: 1.799 acc: 34.26 time: 2.29\n","[2,   300] loss: 1.765 acc: 36.18 time: 2.30\n","TESTING:\n","Accuracy of the network on the 10000 test images: 37.75 %\n","Average loss on the 10000 test images: 1.721\n","[3,   100] loss: 1.748 acc: 36.45 time: 2.39\n","[3,   200] loss: 1.737 acc: 37.10 time: 2.30\n","[3,   300] loss: 1.751 acc: 36.88 time: 2.30\n","TESTING:\n","Accuracy of the network on the 10000 test images: 40.59 %\n","Average loss on the 10000 test images: 1.657\n","[4,   100] loss: 1.727 acc: 37.89 time: 2.37\n","[4,   200] loss: 1.711 acc: 38.30 time: 2.29\n","[4,   300] loss: 1.714 acc: 38.59 time: 2.30\n","TESTING:\n","Accuracy of the network on the 10000 test images: 40.21 %\n","Average loss on the 10000 test images: 1.646\n","[5,   100] loss: 1.706 acc: 38.33 time: 2.38\n","[5,   200] loss: 1.713 acc: 38.49 time: 2.33\n","[5,   300] loss: 1.688 acc: 38.55 time: 2.32\n","TESTING:\n","Accuracy of the network on the 10000 test images: 41.83 %\n","Average loss on the 10000 test images: 1.620\n","[6,   100] loss: 1.690 acc: 39.23 time: 2.41\n","[6,   200] loss: 1.689 acc: 39.02 time: 2.31\n","[6,   300] loss: 1.691 acc: 38.95 time: 2.32\n","TESTING:\n","Accuracy of the network on the 10000 test images: 41.96 %\n","Average loss on the 10000 test images: 1.615\n","[7,   100] loss: 1.662 acc: 40.22 time: 2.40\n","[7,   200] loss: 1.682 acc: 38.95 time: 2.27\n","[7,   300] loss: 1.669 acc: 40.34 time: 2.30\n","TESTING:\n","Accuracy of the network on the 10000 test images: 41.91 %\n","Average loss on the 10000 test images: 1.606\n","[8,   100] loss: 1.678 acc: 39.48 time: 2.38\n","[8,   200] loss: 1.661 acc: 40.79 time: 2.29\n","[8,   300] loss: 1.664 acc: 40.33 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 42.35 %\n","Average loss on the 10000 test images: 1.588\n","[9,   100] loss: 1.647 acc: 40.52 time: 2.37\n","[9,   200] loss: 1.660 acc: 40.51 time: 2.33\n","[9,   300] loss: 1.657 acc: 40.59 time: 2.27\n","TESTING:\n","Accuracy of the network on the 10000 test images: 42.32 %\n","Average loss on the 10000 test images: 1.599\n","[10,   100] loss: 1.642 acc: 41.38 time: 2.40\n","[10,   200] loss: 1.648 acc: 40.88 time: 2.30\n","[10,   300] loss: 1.647 acc: 40.77 time: 2.30\n","TESTING:\n","Accuracy of the network on the 10000 test images: 42.28 %\n","Average loss on the 10000 test images: 1.611\n","[11,   100] loss: 1.622 acc: 41.59 time: 2.33\n","[11,   200] loss: 1.600 acc: 42.74 time: 2.25\n","[11,   300] loss: 1.586 acc: 43.15 time: 2.26\n","TESTING:\n","Accuracy of the network on the 10000 test images: 44.38 %\n","Average loss on the 10000 test images: 1.549\n","[12,   100] loss: 1.585 acc: 42.77 time: 2.41\n","[12,   200] loss: 1.577 acc: 43.61 time: 2.32\n","[12,   300] loss: 1.591 acc: 42.95 time: 2.32\n","TESTING:\n","Accuracy of the network on the 10000 test images: 44.86 %\n","Average loss on the 10000 test images: 1.536\n","[13,   100] loss: 1.582 acc: 42.97 time: 2.41\n","[13,   200] loss: 1.571 acc: 43.59 time: 2.32\n","[13,   300] loss: 1.567 acc: 43.98 time: 2.32\n","TESTING:\n","Accuracy of the network on the 10000 test images: 44.66 %\n","Average loss on the 10000 test images: 1.535\n","[14,   100] loss: 1.562 acc: 43.69 time: 2.40\n","[14,   200] loss: 1.559 acc: 44.02 time: 2.31\n","[14,   300] loss: 1.566 acc: 43.43 time: 2.32\n","TESTING:\n","Accuracy of the network on the 10000 test images: 45.16 %\n","Average loss on the 10000 test images: 1.528\n","[15,   100] loss: 1.566 acc: 43.70 time: 2.36\n","[15,   200] loss: 1.576 acc: 43.59 time: 2.28\n","[15,   300] loss: 1.559 acc: 44.25 time: 2.30\n","TESTING:\n","Accuracy of the network on the 10000 test images: 44.91 %\n","Average loss on the 10000 test images: 1.528\n","[16,   100] loss: 1.556 acc: 44.41 time: 2.42\n","[16,   200] loss: 1.543 acc: 44.51 time: 2.33\n","[16,   300] loss: 1.567 acc: 43.84 time: 2.32\n","TESTING:\n","Accuracy of the network on the 10000 test images: 45.11 %\n","Average loss on the 10000 test images: 1.519\n","[17,   100] loss: 1.554 acc: 44.62 time: 2.42\n","[17,   200] loss: 1.554 acc: 44.46 time: 2.33\n","[17,   300] loss: 1.560 acc: 44.12 time: 2.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 44.73 %\n","Average loss on the 10000 test images: 1.524\n","[18,   100] loss: 1.544 acc: 45.07 time: 2.38\n","[18,   200] loss: 1.537 acc: 45.02 time: 2.30\n","[18,   300] loss: 1.559 acc: 44.02 time: 2.33\n","TESTING:\n","Accuracy of the network on the 10000 test images: 45.26 %\n","Average loss on the 10000 test images: 1.519\n","[19,   100] loss: 1.546 acc: 44.78 time: 2.39\n","[19,   200] loss: 1.563 acc: 44.28 time: 2.32\n","[19,   300] loss: 1.535 acc: 44.92 time: 2.32\n","TESTING:\n","Accuracy of the network on the 10000 test images: 45.06 %\n","Average loss on the 10000 test images: 1.515\n","[20,   100] loss: 1.556 acc: 44.70 time: 2.41\n","[20,   200] loss: 1.546 acc: 44.86 time: 2.32\n","[20,   300] loss: 1.541 acc: 45.14 time: 2.26\n","TESTING:\n","Accuracy of the network on the 10000 test images: 45.21 %\n","Average loss on the 10000 test images: 1.517\n","Finished Training\n"]}],"source":["train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"]},{"cell_type":"markdown","metadata":{"id":"WcN54tcNN15U"},"source":["## Supervised training on the pre-trained model (9 points)\n","In this section, we will load the ResNet18 model pre-trained on the rotation task and re-train the whole model on the classification task.\n","\n","**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"9xR9h_S1N6Xi"},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18\n","\n","#####################################################\n","#     TODO: Load the pre-trained ResNet18 model     #  \n","#####################################################\n","# net.load_state_dict(torch.load('A4-1save.pt'))\n","pretrained_dict = torch.load('A4-1save.pt')  \n","net_dict = net.state_dict()\n","\n","pretrained_dict = {k: v for k, v in pretrained_dict.items() if not k.startswith('fc.')}  \n","\n","\n","net_dict.update(pretrained_dict) \n","net.load_state_dict(net_dict)\n","\n","net.load_state_dict(torch.load('A4-2save.pt'), strict=False)\n","\n","\n","print(net) # print your model and check the num_classes is correct\n","#####################################################\n","#                End of your code                   #   \n","#####################################################"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"gGozc2cM0ADw"},"outputs":[],"source":["# TODO: Define criterion and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=1e-4)"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"JGWW7gzCz_Bu"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1,   100] loss: 1.103 acc: 60.47 time: 2.45\n","[1,   200] loss: 1.008 acc: 64.04 time: 2.35\n","[1,   300] loss: 0.946 acc: 66.38 time: 2.35\n","TESTING:\n","Accuracy of the network on the 10000 test images: 71.54 %\n","Average loss on the 10000 test images: 0.815\n","[2,   100] loss: 0.848 acc: 70.56 time: 2.40\n","[2,   200] loss: 0.834 acc: 71.13 time: 2.28\n","[2,   300] loss: 0.820 acc: 71.58 time: 2.27\n","TESTING:\n","Accuracy of the network on the 10000 test images: 73.50 %\n","Average loss on the 10000 test images: 0.777\n","[3,   100] loss: 0.766 acc: 73.11 time: 2.40\n","[3,   200] loss: 0.747 acc: 73.84 time: 2.30\n","[3,   300] loss: 0.736 acc: 74.18 time: 2.27\n","TESTING:\n","Accuracy of the network on the 10000 test images: 74.40 %\n","Average loss on the 10000 test images: 0.732\n","[4,   100] loss: 0.710 acc: 74.96 time: 2.42\n","[4,   200] loss: 0.707 acc: 75.56 time: 2.32\n","[4,   300] loss: 0.679 acc: 76.11 time: 2.31\n"]},{"name":"stderr","output_type":"stream","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"name":"stdout","output_type":"stream","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 76.68 %\n","Average loss on the 10000 test images: 0.672\n","[5,   100] loss: 0.651 acc: 77.44 time: 2.42\n","[5,   200] loss: 0.660 acc: 77.09 time: 2.31\n","[5,   300] loss: 0.637 acc: 78.12 time: 2.31\n"]},{"name":"stderr","output_type":"stream","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"name":"stdout","output_type":"stream","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 76.73 %\n","Average loss on the 10000 test images: 0.661\n","[6,   100] loss: 0.619 acc: 78.29 time: 2.43\n","[6,   200] loss: 0.613 acc: 78.73 time: 2.32\n","[6,   300] loss: 0.618 acc: 78.33 time: 2.30\n","TESTING:\n","Accuracy of the network on the 10000 test images: 79.04 %\n","Average loss on the 10000 test images: 0.615\n","[7,   100] loss: 0.602 acc: 79.02 time: 2.42\n","[7,   200] loss: 0.576 acc: 79.92 time: 2.36\n","[7,   300] loss: 0.586 acc: 79.65 time: 2.35\n","TESTING:\n","Accuracy of the network on the 10000 test images: 78.58 %\n","Average loss on the 10000 test images: 0.624\n","[8,   100] loss: 0.574 acc: 79.94 time: 2.45\n","[8,   200] loss: 0.573 acc: 80.16 time: 2.33\n","[8,   300] loss: 0.568 acc: 80.09 time: 2.34\n","TESTING:\n","Accuracy of the network on the 10000 test images: 78.78 %\n","Average loss on the 10000 test images: 0.627\n","[9,   100] loss: 0.529 acc: 81.38 time: 2.41\n","[9,   200] loss: 0.561 acc: 81.02 time: 2.30\n","[9,   300] loss: 0.532 acc: 81.55 time: 2.33\n","TESTING:\n","Accuracy of the network on the 10000 test images: 79.91 %\n","Average loss on the 10000 test images: 0.592\n","[10,   100] loss: 0.513 acc: 82.23 time: 2.44\n","[10,   200] loss: 0.528 acc: 81.97 time: 2.32\n","[10,   300] loss: 0.538 acc: 81.41 time: 2.33\n"]},{"name":"stderr","output_type":"stream","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"name":"stdout","output_type":"stream","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 80.50 %\n","Average loss on the 10000 test images: 0.574\n","[11,   100] loss: 0.478 acc: 83.40 time: 2.38\n","[11,   200] loss: 0.441 acc: 85.02 time: 2.27\n","[11,   300] loss: 0.440 acc: 84.83 time: 2.28\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.84 %\n","Average loss on the 10000 test images: 0.502\n","[12,   100] loss: 0.426 acc: 85.60 time: 2.46\n","[12,   200] loss: 0.420 acc: 85.58 time: 2.34\n","[12,   300] loss: 0.411 acc: 85.76 time: 2.34\n"]},{"name":"stderr","output_type":"stream","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"name":"stdout","output_type":"stream","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 82.84 %\n","Average loss on the 10000 test images: 0.504\n","[13,   100] loss: 0.410 acc: 85.86 time: 2.37\n","[13,   200] loss: 0.402 acc: 86.06 time: 2.27\n","[13,   300] loss: 0.400 acc: 86.00 time: 2.28\n"]},{"name":"stderr","output_type":"stream","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"name":"stdout","output_type":"stream","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 83.34 %\n","Average loss on the 10000 test images: 0.500\n","[14,   100] loss: 0.402 acc: 86.10 time: 2.38\n","[14,   200] loss: 0.396 acc: 86.26 time: 2.27\n","[14,   300] loss: 0.400 acc: 86.16 time: 2.27\n"]},{"name":"stderr","output_type":"stream","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"name":"stdout","output_type":"stream","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 83.02 %\n","Average loss on the 10000 test images: 0.502\n","[15,   100] loss: 0.395 acc: 86.60 time: 2.44\n","[15,   200] loss: 0.398 acc: 86.22 time: 2.33\n","[15,   300] loss: 0.390 acc: 86.43 time: 2.34\n"]},{"name":"stderr","output_type":"stream","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"name":"stdout","output_type":"stream","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 83.25 %\n","Average loss on the 10000 test images: 0.495\n","[16,   100] loss: 0.377 acc: 87.55 time: 2.42\n","[16,   200] loss: 0.394 acc: 86.38 time: 2.31\n","[16,   300] loss: 0.392 acc: 86.38 time: 2.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 83.16 %\n","Average loss on the 10000 test images: 0.495\n","[17,   100] loss: 0.364 acc: 87.31 time: 2.45\n","[17,   200] loss: 0.392 acc: 86.03 time: 2.33\n","[17,   300] loss: 0.390 acc: 86.60 time: 2.33\n","TESTING:\n","Accuracy of the network on the 10000 test images: 83.24 %\n","Average loss on the 10000 test images: 0.491\n","[18,   100] loss: 0.374 acc: 87.05 time: 2.45\n","[18,   200] loss: 0.384 acc: 87.04 time: 2.30\n","[18,   300] loss: 0.382 acc: 86.73 time: 2.33\n","TESTING:\n","Accuracy of the network on the 10000 test images: 83.46 %\n","Average loss on the 10000 test images: 0.489\n","[19,   100] loss: 0.373 acc: 87.19 time: 2.42\n","[19,   200] loss: 0.373 acc: 86.92 time: 2.34\n","[19,   300] loss: 0.383 acc: 86.75 time: 2.33\n","TESTING:\n","Accuracy of the network on the 10000 test images: 83.66 %\n","Average loss on the 10000 test images: 0.490\n","[20,   100] loss: 0.380 acc: 86.84 time: 2.37\n","[20,   200] loss: 0.366 acc: 87.27 time: 2.27\n","[20,   300] loss: 0.379 acc: 87.08 time: 2.29\n"]},{"name":"stderr","output_type":"stream","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa81bcc13f0>\n","Traceback (most recent call last):\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/home/cvlab/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/home/cvlab/anaconda3/envs/stanet/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"name":"stdout","output_type":"stream","text":["TESTING:\n","Accuracy of the network on the 10000 test images: 83.47 %\n","Average loss on the 10000 test images: 0.494\n","Finished Training\n"]}],"source":["train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"]},{"cell_type":"markdown","metadata":{"id":"xjVTp9jhefTi"},"source":["## Supervised training on the randomly initialized model (9 points)\n","In this section, we will randomly initialize a ResNet18 model and re-train the whole model on the classification task."]},{"cell_type":"code","execution_count":38,"metadata":{"id":"uEjy8TBieeLK"},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18\n","\n","#################################################\n","# TODO: Randomly initialize a ResNet18 model    #\n","#################################################\n","#Kaiming initialization\n","\n","net = resnet18()\n","def kaiming_init(m):\n","    if isinstance(m, nn.Conv2d):\n","        torch.nn.init.kaiming_normal_(m.weight)\n","net.apply(kaiming_init)\n","\n","net.fc = nn.Linear(512,10)\n","net = net.to(device)\n","print(net) # print your model and check the num_classes is correct\n","#################################################\n","#              End of your code                 #\n","#################################################"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"jEY90pK_0ZAm"},"outputs":[],"source":["# TODO: Define criterion and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=1e-4)"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"lMDwelhY0auO"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1,   100] loss: 2.205 acc: 25.31 time: 2.43\n","[1,   200] loss: 1.844 acc: 33.88 time: 2.33\n","[1,   300] loss: 1.691 acc: 38.73 time: 2.32\n","TESTING:\n","Accuracy of the network on the 10000 test images: 43.56 %\n","Average loss on the 10000 test images: 1.584\n","[2,   100] loss: 1.531 acc: 44.44 time: 2.46\n","[2,   200] loss: 1.475 acc: 46.45 time: 2.34\n","[2,   300] loss: 1.389 acc: 49.49 time: 2.35\n","TESTING:\n","Accuracy of the network on the 10000 test images: 56.18 %\n","Average loss on the 10000 test images: 1.216\n","[3,   100] loss: 1.271 acc: 54.03 time: 2.43\n","[3,   200] loss: 1.241 acc: 54.86 time: 2.31\n","[3,   300] loss: 1.193 acc: 56.56 time: 2.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 60.99 %\n","Average loss on the 10000 test images: 1.095\n","[4,   100] loss: 1.112 acc: 60.48 time: 2.43\n","[4,   200] loss: 1.083 acc: 61.02 time: 2.33\n","[4,   300] loss: 1.065 acc: 62.22 time: 2.32\n","TESTING:\n","Accuracy of the network on the 10000 test images: 63.57 %\n","Average loss on the 10000 test images: 1.063\n","[5,   100] loss: 0.998 acc: 64.69 time: 2.41\n","[5,   200] loss: 0.984 acc: 65.39 time: 2.30\n","[5,   300] loss: 0.957 acc: 66.61 time: 2.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 69.59 %\n","Average loss on the 10000 test images: 0.887\n","[6,   100] loss: 0.902 acc: 68.15 time: 2.42\n","[6,   200] loss: 0.887 acc: 69.26 time: 2.30\n","[6,   300] loss: 0.873 acc: 69.11 time: 2.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 68.14 %\n","Average loss on the 10000 test images: 0.939\n","[7,   100] loss: 0.844 acc: 70.66 time: 2.40\n","[7,   200] loss: 0.827 acc: 71.06 time: 2.31\n","[7,   300] loss: 0.823 acc: 70.98 time: 2.30\n","TESTING:\n","Accuracy of the network on the 10000 test images: 69.29 %\n","Average loss on the 10000 test images: 0.882\n","[8,   100] loss: 0.779 acc: 72.59 time: 2.41\n","[8,   200] loss: 0.752 acc: 73.88 time: 2.30\n","[8,   300] loss: 0.772 acc: 72.79 time: 2.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 73.89 %\n","Average loss on the 10000 test images: 0.759\n","[9,   100] loss: 0.737 acc: 74.80 time: 2.44\n","[9,   200] loss: 0.718 acc: 75.33 time: 2.33\n","[9,   300] loss: 0.717 acc: 75.16 time: 2.32\n","TESTING:\n","Accuracy of the network on the 10000 test images: 75.19 %\n","Average loss on the 10000 test images: 0.720\n","[10,   100] loss: 0.696 acc: 75.90 time: 2.42\n","[10,   200] loss: 0.687 acc: 75.80 time: 2.31\n","[10,   300] loss: 0.690 acc: 75.88 time: 2.33\n","TESTING:\n","Accuracy of the network on the 10000 test images: 76.67 %\n","Average loss on the 10000 test images: 0.695\n","[11,   100] loss: 0.610 acc: 78.94 time: 2.41\n","[11,   200] loss: 0.557 acc: 80.59 time: 2.30\n","[11,   300] loss: 0.564 acc: 80.26 time: 2.27\n","TESTING:\n","Accuracy of the network on the 10000 test images: 80.61 %\n","Average loss on the 10000 test images: 0.566\n","[12,   100] loss: 0.534 acc: 81.22 time: 2.37\n","[12,   200] loss: 0.519 acc: 81.81 time: 2.27\n","[12,   300] loss: 0.515 acc: 82.12 time: 2.27\n","TESTING:\n","Accuracy of the network on the 10000 test images: 80.67 %\n","Average loss on the 10000 test images: 0.554\n","[13,   100] loss: 0.501 acc: 82.86 time: 2.44\n","[13,   200] loss: 0.511 acc: 82.15 time: 2.34\n","[13,   300] loss: 0.501 acc: 82.59 time: 2.35\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.40 %\n","Average loss on the 10000 test images: 0.540\n","[14,   100] loss: 0.491 acc: 82.52 time: 2.45\n","[14,   200] loss: 0.494 acc: 82.59 time: 2.35\n","[14,   300] loss: 0.480 acc: 83.20 time: 2.34\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.74 %\n","Average loss on the 10000 test images: 0.535\n","[15,   100] loss: 0.488 acc: 83.03 time: 2.46\n","[15,   200] loss: 0.468 acc: 83.07 time: 2.33\n","[15,   300] loss: 0.485 acc: 83.15 time: 2.33\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.71 %\n","Average loss on the 10000 test images: 0.533\n","[16,   100] loss: 0.479 acc: 83.16 time: 2.42\n","[16,   200] loss: 0.472 acc: 83.24 time: 2.32\n","[16,   300] loss: 0.453 acc: 84.44 time: 2.31\n","TESTING:\n","Accuracy of the network on the 10000 test images: 81.85 %\n","Average loss on the 10000 test images: 0.525\n","[17,   100] loss: 0.443 acc: 84.26 time: 2.43\n","[17,   200] loss: 0.462 acc: 83.45 time: 2.33\n","[17,   300] loss: 0.467 acc: 83.86 time: 2.34\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.21 %\n","Average loss on the 10000 test images: 0.522\n","[18,   100] loss: 0.454 acc: 84.02 time: 2.45\n","[18,   200] loss: 0.456 acc: 84.27 time: 2.35\n","[18,   300] loss: 0.434 acc: 84.88 time: 2.35\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.24 %\n","Average loss on the 10000 test images: 0.518\n","[19,   100] loss: 0.435 acc: 84.92 time: 2.45\n","[19,   200] loss: 0.428 acc: 85.04 time: 2.34\n","[19,   300] loss: 0.429 acc: 85.02 time: 2.34\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.14 %\n","Average loss on the 10000 test images: 0.522\n","[20,   100] loss: 0.422 acc: 85.21 time: 2.40\n","[20,   200] loss: 0.424 acc: 84.97 time: 2.30\n","[20,   300] loss: 0.435 acc: 84.75 time: 2.29\n","TESTING:\n","Accuracy of the network on the 10000 test images: 82.60 %\n","Average loss on the 10000 test images: 0.523\n","Finished Training\n"]}],"source":["train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"]},{"cell_type":"markdown","metadata":{},"source":["# Write report (37 points)\n","\n","本次作業主要有3個tasks需要大家完成，在A4.pdf中有希望大家達成的baseline **(不能低於baseline最多2%，沒有達到不會給全部分數)**，report的撰寫請大家根據以下要求完成，就請大家將嘗試的結果寫在report裡，祝大家順利！\n","\n","1. (13 points) Train a ResNet18 on the Rotation task and report the test performance. Discuss why such a task helps in learning features that are generalizable to other visual tasks.\n","\n","2. (12 points) Initializing from the Rotation model or from random weights, fine-tune only the weights of the final block of convolutional layers and linear layer on the supervised CIFAR10 classification task. Report the test results and compare the performance of these two models. Provide your observations and insights. You can also discuss how the performance of pre-trained models affects downstream tasks, the performance of fine-tuning different numbers of layers, and so on.\n","\n","3. (12 points) Initializing from the Rotation model or from random weights, train the full network on the supervised CIFAR10 classification task. Report the test results and compare the performance of these two models. Provide your observations and insights."]},{"cell_type":"markdown","metadata":{},"source":["# Extra Credit (13 points)\n","\n","上面基本的code跟report最高可以拿到87分，這個加分部分並沒有要求同學們一定要做，若同學們想要獲得更高的分數可以根據以下的加分要求來獲得加分。\n","\n","- In Figure 5(b) from the Gidaris et al. paper, the authors show a plot of CIFAR10 classification performance vs. number of training examples per category for a supervised CIFAR10 model vs. a RotNet model with the final layers fine-tuned on CIFAR10. The plot shows that pre-training on the Rotation task can be advantageous when only a small amount of labeled data is available. Using your RotNet fine-tuning code and supervised CIFAR10 training code from the main assignment, try to create a similar plot by performing supervised fine-tuning/training on only a subset of CIFAR10.\n","- Use a more advanced model than ResNet18 to try to get higher accuracy on the rotation prediction task, as well as for transfer to supervised CIFAR10 classification.\n","  \n","- If you have a good amount of compute at your disposal, try to train a rotation prediction model on the larger ImageNette dataset (still smaller than ImageNet, though).\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1qQ3NEaCUln7yDSksrEOnDwrt3u9dYNr4","timestamp":1677623843954}]},"gpuClass":"standard","kernelspec":{"display_name":"stanet","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"c7ec909f29cc7664e59f409ce5bbefce5c883cf4d2f920229cefbff32b756732"}}},"nbformat":4,"nbformat_minor":0}
